#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# obeyx_ai_core/smart_loader_pro.py
# Ù†Ø¸Ø§Ù… ØªØ­Ù…ÙŠÙ„ Ø°ÙƒÙŠ Ø®Ø§Ø±Ù‚ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ

import os
import sys
import time
import threading
import importlib
import shutil
import psutil
import platform
import torch
import gc
import requests
import concurrent.futures
import json
import hashlib
import asyncio
import subprocess
import logging
import traceback
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple, Callable
from collections import OrderedDict, deque
from dataclasses import dataclass, field

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© =====
MAX_CONCURRENT_LOAD = 4  # Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ Ù†Ù…Ø§Ø°Ø¬ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
MODEL_CACHE_SIZE = 5     # Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ¨Ù‚Ù‰ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
LOW_POWER_THRESHOLD = 20 # Ù†Ø³Ø¨Ø© Ø§Ù„Ø¨Ø·Ø§Ø±ÙŠØ© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ù„ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ Ø§Ù„ØªÙˆÙÙŠØ±
HIGH_TEMP_THRESHOLD = 75 # Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ø¹Ø¸Ù…Ù‰ (Ù…Ø¦ÙˆÙŠØ©) Ù‚Ø¨Ù„ ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ¨Ø±ÙŠØ¯
PERFORMANCE_MODES = ['extreme', 'balanced', 'power_saver']
DEFAULT_PERFORMANCE_MODE = 'balanced'
MODEL_REPOSITORY = "https://models.obeyx.ai/v2/"

# ===== Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© =====
@dataclass
class ModelMetadata:
    name: str
    version: str
    dependencies: List[str]
    memory_usage: float  # Ø¨Ø§Ù„Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª
    priority: int = 5    # 1-10 (10 = Ø§Ù„Ø£Ù‡Ù…)
    last_used: float = 0
    load_count: int = 0

@dataclass
class SystemDiagnostics:
    cpu_usage: List[float] = field(default_factory=list)
    ram_usage: List[float] = field(default_factory=list)
    gpu_usage: List[float] = field(default_factory=list)
    network_usage: List[float] = field(default_factory=list)
    anomalies: List[Dict] = field(default_factory=list)

# ===== Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… =====
loaded_models: Dict[str, Any] = OrderedDict()
model_metadata: Dict[str, ModelMetadata] = {}
system_report: Dict[str, Any] = {}
load_log: deque = deque(maxlen=1000)  # Ø³Ø¬Ù„ Ø¯Ø§Ø¦Ø±ÙŠ
error_log: deque = deque(maxlen=500)
optimization_flags: List[str] = []
model_response_times: Dict[str, float] = {}
live_status: Dict[str, Any] = {}
diagnostics_data = SystemDiagnostics()
performance_mode: str = DEFAULT_PERFORMANCE_MODE
model_cache = OrderedDict()  # LRU Cache Ù„Ù„Ù†Ù…Ø§Ø°Ø¬
adaptive_learning = {
    'model_usage_patterns': {},
    'system_behavior': {}
}

# ===== ØªØ³Ø¬ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… =====
class SmartLogger:
    def __init__(self):
        self.logger = logging.getLogger('SmartLoaderPro')
        self.logger.setLevel(logging.DEBUG)
        formatter = logging.Formatter('[%(asctime)s] [%(levelname)s] %(message)s', 
                                     datefmt='%Y-%m-%d %H:%M:%S')
        
        # ØªØ³Ø¬ÙŠÙ„ Ø¥Ù„Ù‰ Ù…Ù„Ù
        file_handler = logging.FileHandler('smart_loader.log')
        file_handler.setFormatter(formatter)
        self.logger.addHandler(file_handler)
        
        # ØªØ³Ø¬ÙŠÙ„ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­ÙƒÙ…
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
    
    def log(self, msg: str, level: str = 'info'):
        stamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        entry = f"[SmartLoaderPro - {stamp}] {msg}"
        
        if level == 'info':
            self.logger.info(msg)
            load_log.append(entry)
        elif level == 'error':
            self.logger.error(msg)
            error_log.append(entry)
        elif level == 'warning':
            self.logger.warning(msg)
            load_log.append(f"[WARN] {entry}")
        elif level == 'debug':
            self.logger.debug(msg)
        
        # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        live_status['last_log'] = entry

logger = SmartLogger()

# ===== ÙØ­Øµ Ø¨ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… =====
def scan_system() -> Dict[str, Any]:
    """ÙØ­Øµ Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"""
    try:
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
        cpu_info = {
            'cores': psutil.cpu_count(logical=False),
            'logical_cores': psutil.cpu_count(logical=True),
            'usage': psutil.cpu_percent(interval=0.5),
            'freq': psutil.cpu_freq().current if hasattr(psutil, 'cpu_freq') else None
        }
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        mem = psutil.virtual_memory()
        ram_info = {
            'total': round(mem.total / (1024**3), 2),
            'available': round(mem.available / (1024**3), 2),
            'used': round(mem.used / (1024**3), 2),
            'percent': mem.percent
        }
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª GPU
        gpu_info = {}
        if torch.cuda.is_available():
            gpu_info = {
                'name': torch.cuda.get_device_name(0),
                'memory_total': round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2),
                'memory_allocated': round(torch.cuda.memory_allocated(0) / (1024**3), 2),
                'memory_cached': round(torch.cuda.memory_reserved(0) / (1024**3), 2)
            }
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        os_info = {
            'system': platform.system(),
            'release': platform.release(),
            'version': platform.version(),
            'machine': platform.machine()
        }
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ©
        net_info = {
            'speed': get_network_speed(),
            'latency': get_network_latency()
        }
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·Ø§Ù‚Ø©
        power_info = get_power_status()
        
        # ØªØ­Ø¯ÙŠØ« ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù…
        system_report.update({
            'cpu': cpu_info,
            'ram': ram_info,
            'gpu': gpu_info,
            'os': os_info,
            'torch_version': torch.__version__,
            'python_version': platform.python_version(),
            'network': net_info,
            'power': power_info,
            'timestamp': time.time(),
            'performance_mode': performance_mode
        })
        
        logger.log(f"âœ… System Scan: CPU={cpu_info['usage']}% | RAM={ram_info['used']}/{ram_info['total']}GB | GPU={gpu_info.get('name', 'None')}", 'info')
        return system_report
    except Exception as e:
        logger.log(f"System scan failed: {traceback.format_exc()}", 'error')
        return {}

def get_network_speed() -> float:
    """Ù‚ÙŠØ§Ø³ Ø³Ø±Ø¹Ø© Ø§Ù„Ø´Ø¨ÙƒØ© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©"""
    try:
        test_file = "https://speedtest.obeyx.ai/100mb.test"
        start = time.perf_counter()
        with requests.get(test_file, stream=True, timeout=10) as r:
            r.raise_for_status()
            total_bytes = 0
            for chunk in r.iter_content(chunk_size=8192):
                total_bytes += len(chunk)
                if time.perf_counter() - start > 5:  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 5 Ø«ÙˆØ§Ù†
                    break
        elapsed = time.perf_counter() - start
        speed = (total_bytes / (1024**2)) / elapsed  # MB/s
        return round(speed, 2)
    except:
        return 0.0

def get_network_latency() -> float:
    """Ù‚ÙŠØ§Ø³ Ø²Ù…Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø´Ø¨ÙƒØ©"""
    try:
        target = "8.8.8.8"
        start = time.perf_counter()
        subprocess.run(["ping", "-c", "1", target], stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=2)
        return round((time.perf_counter() - start) * 1000, 2)  # Ù…Ù„Ù„ÙŠ Ø«Ø§Ù†ÙŠØ©
    except:
        return -1.0

def get_power_status() -> Dict[str, Any]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ø§Ù‚Ø© ÙˆØ§Ù„Ù†Ø¸Ø§Ù…"""
    try:
        battery = psutil.sensors_battery() if hasattr(psutil, 'sensors_battery') else None
        return {
            'plugged': battery.power_plugged if battery else None,
            'percent': battery.percent if battery else None,
            'power_time': battery.secsleft if battery else None,
            'low_power': battery.percent < LOW_POWER_THRESHOLD if battery and battery.percent else False
        }
    except:
        return {}

# ===== Ù†Ø¸Ø§Ù… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… =====
def load_model(name: str, priority: int = 5, preload_only: bool = False) -> Any:
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø°ÙƒÙŠØ© Ù„Ù„Ø°Ø§ÙƒØ±Ø©"""
    start_time = time.perf_counter()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
    if name in model_cache:
        model = model_cache[name]
        model_metadata[name].last_used = time.time()
        model_metadata[name].load_count += 1
        logger.log(f"âš¡ï¸ Model '{name}' served from cache (Priority: {priority})", 'info')
        return model
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª
    if not check_dependencies(name):
        logger.log(f"âŒ Model '{name}' dependencies not satisfied", 'error')
        return None
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    try:
        # ØªØ­Ù…ÙŠÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ù„ÙˆØ­Ø¯Ø©
        module_name = f"models.{name}_loader"
        model_module = importlib.import_module(module_name)
        
        # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
        loader_func = getattr(model_module, f"load_{name}")
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        model = loader_func(performance_mode=performance_mode)
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        loaded_models[name] = model
        model_cache[name] = model
        model_cache.move_to_end(name)  # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ±ØªÙŠØ¨ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
        if name not in model_metadata:
            model_metadata[name] = ModelMetadata(
                name=name,
                version=get_model_version(name),
                dependencies=get_model_dependencies(name),
                memory_usage=estimate_model_memory(name, model),
                priority=priority
            )
        
        model_metadata[name].last_used = time.time()
        model_metadata[name].load_count += 1
        
        # ØªØ³Ø¬ÙŠÙ„ Ø²Ù…Ù† Ø§Ù„ØªØ­Ù…ÙŠÙ„
        elapsed = round(time.perf_counter() - start_time, 2)
        model_response_times[name] = elapsed
        logger.log(f"ğŸ” Model '{name}' loaded in {elapsed}s (Priority: {priority})", 'info')
        
        # Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ù†Ù…Ø· Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        adaptive_learning['model_usage_patterns'][name] = adaptive_learning['model_usage_patterns'].get(name, 0) + 1
        
        return model if not preload_only else None
        
    except Exception as e:
        logger.log(f"Failed to load model '{name}': {traceback.format_exc()}", 'error')
        return None

def unload_model(name: str) -> bool:
    """ØªÙØ±ÙŠØº Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    try:
        if name in loaded_models:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¯Ø¹Ù… Ø°Ù„Ùƒ
            if hasattr(loaded_models[name], 'cleanup'):
                loaded_models[name].cleanup()
            
            # Ø­Ø°Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            del loaded_models[name]
            
            # Ø­Ø°Ù Ù…Ù† Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            if name in model_cache:
                del model_cache[name]
            
            logger.log(f"â™»ï¸ Unloaded model '{name}' to free memory", 'info')
            return True
        return False
    except Exception as e:
        logger.log(f"Failed to unload model '{name}': {e}", 'error')
        return False

def manage_model_cache() -> None:
    """Ø¥Ø¯Ø§Ø±Ø© Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    # ØªÙØ±ÙŠØº Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ù‚Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‹Ø§ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
    while len(model_cache) > MODEL_CACHE_SIZE:
        name, _ = model_cache.popitem(last=False)
        unload_model(name)
    
    # ØªÙØ±ÙŠØº Ø¥Ø¶Ø§ÙÙŠ Ø¹Ù†Ø¯ Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    mem_available = system_report.get('ram', {}).get('available', 0)
    if mem_available < 1.0:  # Ø£Ù‚Ù„ Ù…Ù† 1GB Ù…ØªØ§Ø­Ø©
        logger.log("âš ï¸ Low memory detected - freeing model cache", 'warning')
        for name in list(model_cache.keys())[:-2]:  # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† ÙÙ‚Ø·
            if name in model_cache:
                unload_model(name)

def check_dependencies(model_name: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    # Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ù„ØªØ¨Ø¹ÙŠØ§Øª - ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø³ÙŠØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©
    required_deps = ['torch', 'transformers', 'numpy']
    for dep in required_deps:
        try:
            importlib.import_module(dep)
        except ImportError:
            logger.log(f"âŒ Missing dependency '{dep}' for model '{model_name}'", 'error')
            return False
    return True

def get_model_version(model_name: str) -> str:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù…Ø­Ø§ÙƒØ§Ø©)"""
    return "1.2.0"  # ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø³ÙŠØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ

def get_model_dependencies(model_name: str) -> List[str]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù…Ø­Ø§ÙƒØ§Ø©)"""
    return ['torch>=1.10', 'transformers>=4.18']  # ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø³ÙŠØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ

def estimate_model_memory(model_name: str, model_obj: Any) -> float:
    """ØªÙ‚Ø¯ÙŠØ± Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
    # Ù…Ø­Ø§ÙƒØ§Ø© - ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø³ÙŠØªÙ… Ù‚ÙŠØ§Ø³ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
    if 'llm' in model_name:
        return 3.2
    elif 'vision' in model_name:
        return 1.8
    return 0.5

# ===== Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ Ø§Ù„Ø°ÙƒÙŠ =====
def parallel_model_loader(model_list: List[Tuple[str, int]]) -> Dict[str, Any]:
    """ØªØ­Ù…ÙŠÙ„ Ù…ØªÙˆØ§Ø²ÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª"""
    results = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_CONCURRENT_LOAD) as executor:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„
        future_to_model = {
            executor.submit(load_model, name, priority): name 
            for name, priority in model_list
        }
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ù†Ø¯ Ø§ÙƒØªÙ…Ø§Ù„Ù‡Ø§
        for future in concurrent.futures.as_completed(future_to_model):
            model_name = future_to_model[future]
            try:
                results[model_name] = future.result()
            except Exception as e:
                logger.log(f"Parallel load failed for {model_name}: {e}", 'error')
                results[model_name] = None
    
    # ØªÙ‚Ø¯ÙŠØ± Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒØ§Ø¡
    estimate_intelligence_level()
    
    return results

# ===== Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© =====
def auto_optimize_system() -> None:
    """Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¸Ø±ÙˆÙ Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©
        if system_report.get('cpu', {}).get('temp', 0) > HIGH_TEMP_THRESHOLD:
            set_performance_mode('power_saver')
            logger.log("â„ï¸ Enabled cooling mode due to high temperature", 'warning')
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ø§Ù‚Ø©
        power_status = system_report.get('power', {})
        if power_status.get('low_power', False):
            set_performance_mode('power_saver')
            logger.log("ğŸ”‹ Enabled power saver mode", 'info')
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        mem_usage = system_report.get('ram', {}).get('percent', 0)
        if mem_usage > 85:
            logger.log("âš ï¸ High memory usage - optimizing model cache", 'warning')
            manage_model_cache()
        
        # ØªØ­Ø³ÙŠÙ† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Torch
        optimize_torch_settings()
        
        # ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù…ØªÙˆÙ‚Ø¹Ø©
        predict_and_preload_models()
        
    except Exception as e:
        logger.log(f"Auto-optimization failed: {e}", 'error')

def set_performance_mode(mode: str) -> None:
    """ØªØºÙŠÙŠØ± ÙˆØ¶Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„Ù†Ø¸Ø§Ù…"""
    global performance_mode
    if mode in PERFORMANCE_MODES:
        performance_mode = mode
        system_report['performance_mode'] = mode
        logger.log(f"âš™ï¸ Performance mode changed to '{mode}'", 'info')
        
        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©
        for model_name in list(model_cache.keys()):
            if model_metadata[model_name].priority >= 7:  # Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ÙÙ‚Ø·
                unload_model(model_name)
                load_model(model_name, model_metadata[model_name].priority)
    else:
        logger.log(f"Invalid performance mode: {mode}", 'error')

def optimize_torch_settings() -> None:
    """ØªØ­Ø³ÙŠÙ† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª PyTorch Ù„Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ù…Ø«Ù„"""
    try:
        if torch.cuda.is_available():
            # Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ CUDA
            torch.backends.cudnn.benchmark = True
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            
            # Ø¥Ø¯Ø§Ø±Ø© Ø°Ø§ÙƒØ±Ø© Ø£ÙØ¶Ù„
            torch.cuda.empty_cache()
            
            logger.log("âš™ï¸ Optimized CUDA settings for better performance", 'info')
        
        if torch.backends.mps.is_available():
            # Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ø£Ù†Ø¸Ù…Ø© Apple Silicon
            torch.backends.mps.set_per_process_memory_fraction(0.75)
            logger.log("ğŸ Optimized MPS settings for Apple Silicon", 'info')
    except Exception as e:
        logger.log(f"Torch optimization failed: {e}", 'error')

# ===== Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„ØªÙƒÙŠÙÙŠ =====
def predict_and_preload_models() -> None:
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
    try:
        # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        usage_patterns = adaptive_learning.get('model_usage_patterns', {})
        if not usage_patterns:
            return
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‹Ø§
        sorted_models = sorted(usage_patterns.items(), key=lambda x: x[1], reverse=True)
        
        # ØªØ­Ù…ÙŠÙ„ Ù…Ø³Ø¨Ù‚ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©
        for model_name, count in sorted_models[:2]:  # ØªØ­Ù…ÙŠÙ„ Ù…Ø³Ø¨Ù‚ Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†
            if model_name not in model_cache:
                logger.log(f"ğŸ”® Pre-loading predicted model: {model_name}", 'info')
                load_model(model_name, priority=6, preload_only=True)
    except Exception as e:
        logger.log(f"Predictive pre-load failed: {e}", 'error')

def estimate_intelligence_level() -> None:
    """ØªÙ‚Ø¯ÙŠØ± Ù…Ø³ØªÙˆÙ‰ Ø°ÙƒØ§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚Ø¯Ø±Ø§ØªÙ‡"""
    try:
        # Ø­Ø³Ø§Ø¨ Ø²Ù…Ù† Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        total_load_time = sum(model_response_times.values())
        
        # ØªØ­Ù„ÙŠÙ„ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        capabilities = []
        if torch.cuda.is_available():
            capabilities.append('gpu_acceleration')
        if len(loaded_models) > 3:
            capabilities.append('multi_model')
        if adaptive_learning.get('model_usage_patterns'):
            capabilities.append('predictive_loading')
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒØ§Ø¡
        if 'gpu_acceleration' in capabilities and total_load_time < 5:
            level = "âš¡ ÙØ§Ø¦Ù‚ Ø§Ù„Ø°ÙƒØ§Ø¡"
            score = 95
        elif len(capabilities) > 2 and total_load_time < 8:
            level = "ğŸ§  Ø°ÙƒÙŠ Ø¬Ø¯Ø§Ù‹"
            score = 85
        elif len(capabilities) > 1:
            level = "ğŸ§  Ø°ÙƒÙŠ"
            score = 75
        else:
            level = "ğŸŒ€ Ø¹Ø§Ø¯ÙŠ"
            score = 60
        
        # ØªØ­Ø¯ÙŠØ« ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù…
        system_report['intelligence_level'] = level
        system_report['intelligence_score'] = score
        system_report['capabilities'] = capabilities
        
        logger.log(f"ğŸ§  Estimated AI Level: {level} (Score: {score})", 'info')
    except Exception as e:
        logger.log(f"Intelligence estimation failed: {e}", 'error')

# ===== Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… =====
async def realtime_monitor() -> None:
    """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ"""
    while True:
        try:
            # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
            scan_system()
            
            # Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ´Ø®ÙŠØµ
            diagnostics_data.cpu_usage.append(psutil.cpu_percent())
            diagnostics_data.ram_usage.append(psutil.virtual_memory().percent)
            
            if torch.cuda.is_available():
                diagnostics_data.gpu_usage.append(torch.cuda.utilization())
            
            # Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø´Ø°ÙˆØ°
            detect_anomalies()
            
            # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­ÙŠ
            update_live_status()
            
            # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù„Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
            await asyncio.sleep(2.5)
            
        except Exception as e:
            logger.log(f"Realtime monitor error: {e}", 'error')
            await asyncio.sleep(5)

def detect_anomalies() -> None:
    """Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø³Ù„ÙˆÙƒ ØºÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…"""
    try:
        # Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ø±ØªÙØ§Ø¹ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©
        if len(diagnostics_data.cpu_usage) > 10:
            last_10 = diagnostics_data.cpu_usage[-10:]
            avg = sum(last_10) / len(last_10)
            if diagnostics_data.cpu_usage[-1] > avg * 1.5:
                anomaly = {
                    'type': 'high_cpu',
                    'value': diagnostics_data.cpu_usage[-1],
                    'timestamp': time.time()
                }
                diagnostics_data.anomalies.append(anomaly)
                logger.log(f"âš ï¸ CPU spike detected: {diagnostics_data.cpu_usage[-1]}%", 'warning')
        
        # Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ø±ØªÙØ§Ø¹ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ ÙÙŠ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©
        if system_report.get('cpu', {}).get('temp', 0) > HIGH_TEMP_THRESHOLD:
            anomaly = {
                'type': 'high_temp',
                'value': system_report['cpu']['temp'],
                'timestamp': time.time()
            }
            diagnostics_data.anomalies.append(anomaly)
            logger.log(f"ğŸŒ¡ï¸ High temperature detected: {system_report['cpu']['temp']}Â°C", 'warning')
    except Exception as e:
        logger.log(f"Anomaly detection failed: {e}", 'error')

def update_live_status() -> None:
    """ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­ÙŠ"""
    live_status.update({
        'timestamp': time.time(),
        'models_loaded': list(model_cache.keys()),
        'model_count': len(model_cache),
        'memory_usage': psutil.virtual_memory().percent,
        'cpu_usage': psutil.cpu_percent(),
        'performance_mode': performance_mode,
        'last_anomaly': diagnostics_data.anomalies[-1] if diagnostics_data.anomalies else None
    })

# ===== ÙˆØ§Ø¬Ù‡Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© =====
def export_diagnostics(filename: str = "system_diagnostics.json") -> bool:
    """ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ´Ø®ÙŠØµ Ø¥Ù„Ù‰ Ù…Ù„Ù"""
    try:
        data = {
            'system_report': system_report,
            'loaded_models': list(model_cache.keys()),
            'model_metadata': {name: vars(md) for name, md in model_metadata.items()},
            'performance_mode': performance_mode,
            'intelligence_level': system_report.get('intelligence_level', 'N/A'),
            'diagnostics': {
                'cpu_usage': diagnostics_data.cpu_usage,
                'ram_usage': diagnostics_data.ram_usage,
                'anomalies': diagnostics_data.anomalies
            },
            'logs': list(load_log),
            'errors': list(error_log),
            'export_time': datetime.now().isoformat()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.log(f"ğŸ“Š Exported diagnostics to {filename}", 'info')
        return True
    except Exception as e:
        logger.log(f"Diagnostics export failed: {e}", 'error')
        return False

def generate_health_report() -> Dict[str, Any]:
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    health_score = 100
    
    # Ø®ØµÙ… Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    error_count = len(error_log)
    if error_count > 10:
        health_score -= 15
    elif error_count > 5:
        health_score -= 10
    elif error_count > 0:
        health_score -= 5
    
    # Ø®ØµÙ… Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ø§Ù„Ø´Ø°ÙˆØ°
    anomaly_count = len(diagnostics_data.anomalies)
    if anomaly_count > 5:
        health_score -= 20
    elif anomaly_count > 2:
        health_score -= 10
    elif anomaly_count > 0:
        health_score -= 5
    
    # Ø®ØµÙ… Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    if system_report.get('ram', {}).get('percent', 0) > 90:
        health_score -= 15
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ÙˆØ¯
    health_score = max(0, min(100, health_score))
    
    return {
        'health_score': health_score,
        'status': 'excellent' if health_score >= 90 else 
                 'good' if health_score >= 75 else 
                 'fair' if health_score >= 60 else 
                 'poor',
        'issue_count': error_count + anomaly_count,
        'last_scan': system_report.get('timestamp', 0),
        'recommendations': generate_recommendations(health_score)
    }

def generate_recommendations(health_score: int) -> List[str]:
    """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    recommendations = []
    
    if health_score < 90:
        recommendations.append("Consider upgrading hardware for better performance")
    
    if system_report.get('ram', {}).get('percent', 0) > 85:
        recommendations.append("Increase system RAM or optimize model memory usage")
    
    if len(error_log) > 5:
        recommendations.append("Review error logs and address recurring issues")
    
    if not recommendations:
        recommendations.append("System is well optimized. No critical recommendations")
    
    return recommendations

# ===== Ø§Ù„ØªÙ‡ÙŠØ¦Ø© ÙˆØ§Ù„ØªØ´ØºÙŠÙ„ =====
def initialize_system() -> None:
    """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ"""
    try:
        logger.log("ğŸš€ Starting SmartLoader Pro - Advanced AI Loading System", 'info')
        
        # Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ù„Ù„Ù†Ø¸Ø§Ù…
        scan_system()
        
        # Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ø£ÙˆÙ„ÙŠ
        auto_optimize_system()
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        essential_models = [
            ('whisper', 9),
            ('llm_core', 10),
            ('vision_base', 8),
            ('audio_processor', 7)
        ]
        parallel_model_loader(essential_models)
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        asyncio.create_task(realtime_monitor())
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ
        smart_cleanup()
        
        logger.log("âœ… SmartLoader Pro initialized successfully. System is operational ğŸ”¥", 'info')
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØµØ­Ø©
        health = generate_health_report()
        logger.log(f"ğŸ“ˆ System Health: {health['health_score']}/100 ({health['status']})", 'info')
        
    except Exception as e:
        logger.log(f"System initialization failed: {traceback.format_exc()}", 'error')
        sys.exit(1)

def smart_cleanup(full: bool = False) -> None:
    """ØªÙ†Ø¸ÙŠÙ Ø°ÙƒÙŠ Ù„Ù„Ø°Ø§ÙƒØ±Ø©"""
    try:
        # ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© Python
        gc.collect()
        
        # ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© GPU Ø¥Ù† ÙˆØ¬Ø¯Øª
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        
        # ØªÙ†Ø¸ÙŠÙ Ø´Ø§Ù…Ù„ Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨
        if full:
            for name in list(model_cache.keys()):
                if model_metadata[name].priority < 8:  # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
                    unload_model(name)
        
        logger.log("ğŸ§¹ Performed advanced memory cleanup", 'info')
    except Exception as e:
        logger.log(f"Memory cleanup failed: {e}", 'error')

# ===== Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© =====
if __name__ == "__main__":
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    initialize_system()
    
    # Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„ØªØ´ØºÙŠÙ„ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©
    try:
        asyncio.get_event_loop().run_forever()
    except KeyboardInterrupt:
        logger.log("ğŸ›‘ SmartLoader Pro stopped by user", 'info')
        export_diagnostics()
        sys.exit(0)
