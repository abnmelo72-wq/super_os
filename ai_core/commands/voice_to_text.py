import os
import sys
import json
import shutil
import sounddevice as sd
import queue
import tempfile
import numpy as np
import threading

from vosk import Model as VoskModel, KaldiRecognizer
import whisper

USE_WHISPER = False  # Ø³ÙŠØªÙ… Ø¶Ø¨Ø·Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡

q = queue.Queue()

def audio_callback(indata, frames, time, status):
    if status:
        print(f"Error: {status}", file=sys.stderr)
    q.put(bytes(indata))

def record_audio(seconds=5, samplerate=16000):
    print("ðŸŽ™ï¸ ØªØ³Ø¬ÙŠÙ„ ØµÙˆØª Ù„Ù…Ø¯Ø©", seconds, "Ø«ÙˆØ§Ù†ÙŠ...")
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        filename = f.name
    with sd.RawInputStream(samplerate=samplerate, blocksize=8000, dtype='int16',
                           channels=1, callback=audio_callback):
        with open(filename, 'wb') as wf:
            for _ in range(0, int(samplerate / 8000 * seconds)):
                wf.write(q.get())
    print("âœ… ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„:", filename)
    return filename

def transcribe_with_vosk(audio_file):
    model_path = "ai_core/models/vosk"
    if not os.path.isdir(model_path):
        print("â¬ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Vosk...")
        os.makedirs(model_path, exist_ok=True)
        # Ø­Ù…Ù‘Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø£Ùˆ Ø¶Ø¹ Ø±Ø§Ø¨Ø· Ø§Ù„ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¥Ù† Ø£Ø±Ø¯Øª
        print("âš ï¸ Ø­Ù…Ù‘Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¯ÙˆÙŠÙ‹Ø§ ÙˆØ¶Ø¹Ù‡ ÙÙŠ:", model_path)
        return ""

    model = VoskModel(model_path)
    rec = KaldiRecognizer(model, 16000)
    with open(audio_file, "rb") as f:
        data = f.read()
        if rec.AcceptWaveform(data):
            result = rec.Result()
        else:
            result = rec.FinalResult()
    text = json.loads(result).get("text", "")
    print("ðŸ—£ï¸ Ù†Øµ Ù…Ø³ØªØ®Ø±Ø¬ (Vosk):", text)
    return text

def transcribe_with_whisper(audio_file):
    print("ðŸ“¥ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper...")
    model = whisper.load_model("base")
    result = model.transcribe(audio_file)
    print("ðŸ—£ï¸ Ù†Øµ Ù…Ø³ØªØ®Ø±Ø¬ (Whisper):", result["text"])
    return result["text"]

def transcribe_audio(auto_select=True):
    audio = record_audio()

    if auto_select:
        ram = shutil.disk_usage("/")[2] // (1024 * 1024)
        USE_WHISPER = ram > 2048  # Ø£ÙƒØ«Ø± Ù…Ù† 2GBØŸ Ø§Ø³ØªØ®Ø¯Ù… Whisper
    try:
        return transcribe_with_whisper(audio) if USE_WHISPER else transcribe_with_vosk(audio)
    finally:
        os.remove(audio)
